{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77273428",
   "metadata": {},
   "source": [
    "  Importa√ß√£o de Bibliotecas e Ferramentas\n",
    "\n",
    "Nesta se√ß√£o, importamos as bibliotecas essenciais para a manipula√ß√£o de dados (`Pandas`) e as ferramentas de transforma√ß√£o do Scikit-learn que utilizaremos nas etapas de pr√©-processamento, como escalonamento e encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25564834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas de Pr√©-Processamento importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # Para Normaliza√ß√£o (Scaling)\n",
    "from sklearn.preprocessing import LabelEncoder  # Para Encoding Categ√≥rico Bin√°rio\n",
    "from sklearn.model_selection import train_test_split # (Opcional, mas boa pr√°tica)\n",
    "\n",
    "print(\"Bibliotecas de Pr√©-Processamento importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876b798",
   "metadata": {},
   "source": [
    "## 2. üì• Carregamento dos Dados e Classifica√ß√£o\n",
    "\n",
    "Carregamos o dataset original e separamos as colunas em listas l√≥gicas (Num√©ricas, Categ√≥ricas e Alvo) para orientar o pr√©-processamento subsequente. A coluna de ID √© removida, pois n√£o √© necess√°ria para o treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5ee7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset carregado com sucesso. Dimens√µes: (12000, 5)\n",
      "\n",
      "Vari√°vel de Regress√£o: Pontuacao_Prova_Final\n",
      "Vari√°veis Num√©ricas (a serem escaladas): ['Idade', 'Horas_Estudo_Semana']\n",
      "Vari√°veis Categ√≥ricas (a serem codificadas): ['Aprovado']\n",
      "Dimens√µes ap√≥s remover ID: (12000, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CSV_FILE = '../students_data.csv' \n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(CSV_FILE)\n",
    "    print(f\"Dataset carregado com sucesso. Dimens√µes: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo {CSV_FILE} n√£o encontrado. Verifique o caminho e o nome do arquivo.\")\n",
    "\n",
    "\n",
    "\n",
    "target_reg = 'Pontuacao_Prova_Final' \n",
    "target_class = 'Aprovado' \n",
    "\n",
    "\n",
    "num_cols = ['Idade', 'Horas_Estudo_Semana'] \n",
    "\n",
    "cat_cols = ['Aprovado'] \n",
    "\n",
    "id_col = 'ID_Aluno'\n",
    "\n",
    "\n",
    "df = df.drop(columns=[id_col])\n",
    "\n",
    "print(f\"\\nVari√°vel de Regress√£o: {target_reg}\")\n",
    "print(f\"Vari√°veis Num√©ricas (a serem escaladas): {num_cols}\")\n",
    "print(f\"Vari√°veis Categ√≥ricas (a serem codificadas): {cat_cols}\")\n",
    "print(f\"Dimens√µes ap√≥s remover ID: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a5df4c",
   "metadata": {},
   "source": [
    "### 3. Tratamento de Valores Faltantes\n",
    "\n",
    "A an√°lise explorat√≥ria mostrou que o dataset j√° est√° limpo, com 0% de valores ausentes em todas as colunas. Nenhuma imputa√ß√£o √© necess√°ria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964a649",
   "metadata": {},
   "source": [
    "### 4. Tratamento de Outliers\n",
    "\n",
    "Os Boxplots e o m√©todo IQR (Intervalo Interquartil) n√£o identificaram outliers nas features num√©ricas. Portanto, n√£o √© necess√°rio aplicar t√©cnicas de Capping ou remo√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6df388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifica√ß√£o ap√≥s Encoding:\n",
      "   Idade  Horas_Estudo_Semana  Pontuacao_Prova_Final  Aprovado\n",
      "0     23                    7                     16         0\n",
      "1     22                   23                     63         1\n",
      "2     18                   10                     33         0\n",
      "3     21                   17                     33         0\n",
      "4     21                   27                     76         1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['Aprovado'] = df['Aprovado'].astype(int)\n",
    "\n",
    "\n",
    "print(\"\\nVerifica√ß√£o ap√≥s Encoding:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77c3efb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features Num√©ricas Normalizadas:\n",
      "      Idade  Horas_Estudo_Semana\n",
      "0  0.984963            -1.498117\n",
      "1  0.482281             0.088836\n",
      "2 -1.528445            -1.200564\n",
      "3 -0.020400            -0.506271\n",
      "4 -0.020400             0.485575\n",
      "\n",
      "Scaler salvo com sucesso em ../models/scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "if not os.path.exists('../models'):\n",
    "    os.makedirs('../models')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "print(\"\\nFeatures Num√©ricas Normalizadas:\")\n",
    "print(df[num_cols].head())\n",
    "\n",
    "\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "print(\"\\nScaler salvo com sucesso em ../models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba46e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nova feature criada:\n",
      "   Horas_por_Idade\n",
      "0        -1.475590\n",
      "1         0.042844\n",
      "2         1.834996\n",
      "3         0.010328\n",
      "4        -0.009906\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['Horas_por_Idade'] = df['Horas_Estudo_Semana'] * df['Idade']\n",
    "\n",
    "print(\"\\nNova feature criada:\")\n",
    "print(df[['Horas_por_Idade']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af172e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset limpo salvo com sucesso em: ../data/students_clean.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.exists('../data'):\n",
    "    os.makedirs('../data')\n",
    "\n",
    "df.to_csv('../data/students_clean.csv', index=False)\n",
    "\n",
    "print(\"\\nDataset limpo salvo com sucesso em: ../data/students_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
