# üìÑ RELAT√ìRIO T√âCNICO FINAL: PREVIS√ÉO DE DESEMPENHO ACAD√äMICO

## 1. Resumo Executivo

Este projeto de Machine Learning (ML) focou no desenvolvimento de um modelo de **Regress√£o** para prever a **Pontua√ß√£o Final da Prova** de estudantes. O objetivo de maximizar o coeficiente de determina√ß√£o ($\text{R¬≤}$) foi atingido com sucesso.

O modelo final selecionado foi o **Random Forest Regressor**, otimizado via Grid Search.

| M√©trica | Desempenho no Teste |
| :--- | :--- |
| **R¬≤** | **0.9562** |
| **MAE** | **4.65** pontos |

O $\text{R}^{2}$ de $0.9562$ demonstra que o modelo √© altamente preditivo, com um erro m√©dio absoluto de aproximadamente $4.65$ pontos na pontua√ß√£o final.

---

## 2. Introdu√ß√£o

### 2.1 Contexto do Problema

A capacidade de prever o desempenho acad√™mico √© um desafio crucial no setor de educa√ß√£o, permitindo interven√ß√µes precoces e personalizadas. O problema de neg√≥cio abordado √©: **"Quais fatores predizem a Pontua√ß√£o Final de um estudante, e qual a acur√°cia de um modelo de Machine Learning para essa previs√£o?"**

### 2.2 Objetivo do Projeto

O objetivo t√©cnico do projeto √© desenvolver e otimizar um modelo de **Regress√£o** que minimize o Erro Absoluto M√©dio (MAE) e maximize o coeficiente de determina√ß√£o ($\text{R¬≤}$).

### 2.3 Metodologia

O projeto seguiu a metodologia padr√£o de Data Science, dividida nas seguintes etapas:
1.  **An√°lise Explorat√≥ria de Dados (EDA):** Identifica√ß√£o de distribui√ß√µes e correla√ß√µes.
2.  **Pr√©-processamento:** Tratamento de *outliers* e codifica√ß√£o de vari√°veis.
3.  **Modelagem e Baseline:** Compara√ß√£o de modelos de ML e estabelecimento de um $\text{R}^{2}$ de refer√™ncia ($\text{Baseline}$) de $\mathbf{R¬≤}=0.65$.
4.  **Otimiza√ß√£o e Tuning:** Ajuste fino dos hiperpar√¢metros do modelo vencedor (Random Forest).
5.  **Relat√≥rio Final e Documenta√ß√£o:** Consolida√ß√£o e comunica√ß√£o dos resultados.

---

## 3. Explora√ß√£o dos Dados

### 3.1 Descri√ß√£o do Dataset e Qualidade

O dataset (`students_clean.csv`) √© composto por **12.000** observa√ß√µes e 5 features (incluindo a vari√°vel alvo). A vari√°vel alvo √© a **`Pontuacao_Prova_Final`**. O dataset √© limpo, sem valores faltantes ($\text{NaN}$) ou *outliers* significativos.

### 3.2 Principais Descobertas da EDA

* **Correla√ß√£o Dominante:** Foi identificada uma **correla√ß√£o extremamente forte e positiva** ($\mathbf{r} \approx \mathbf{+0.97}$) entre a feature **`Horas_Estudo_Semana`** e a vari√°vel alvo, sendo o principal preditor.
* **Vari√°veis Secund√°rias:** A feature **`Idade`** apresentou correla√ß√£o **praticamente nula** ($\mathbf{r} \approx \mathbf{-0.01}$) com a pontua√ß√£o final.

---

## 4. Pr√©-processamento

### 4.1 Feature Engineering

Foi criada a feature **`Horas_por_Idade`** ($\text{Horas\_Estudo\_Semana} / \text{Idade}$) para capturar uma raz√£o de esfor√ßo de estudo em rela√ß√£o √† idade.

### 4.2 Encoding e Normaliza√ß√£o

* **Encoding:** Foi utilizado **Label Encoding** para a vari√°vel bin√°ria `Aprovado` ($\text{True}/\text{False}$), convertendo para $1/0$.
* **Scaling:** Foi aplicado o **StandardScaler** √†s features num√©ricas (`Idade`, `Horas\_Estudo\_Semana`) para garantir m√©dia 0 e desvio padr√£o 1, evitando o dom√≠nio de escala.

---

## 5. Modelagem

### 5.1 Modelos Testados e Sele√ß√£o

O desempenho foi avaliado primariamente pelo $\text{R¬≤}$ e $\text{MAE}$.

| Modelo | R¬≤ (Valida√ß√£o) | MAE (Valida√ß√£o) |
| :--- | :--- | :--- |
| **Baseline (Linear)** | $\mathbf{0.65}$ | N/A (A m√©trica prim√°ria era o R¬≤) |
| **Random Forest Padr√£o** | $\mathbf{0.9567}$ | $\mathbf{4.4930}$ |

* **Sele√ß√£o:** O **Random Forest Regressor** foi selecionado devido ao seu desempenho significativamente superior ao baseline linear ($\text{R¬≤}=0.9567$), indicando que este modelo de *ensemble* captura melhor a estrutura de dados.

---

## 6. Otimiza√ß√£o

### 6.1 Processo de Tuning

Foi aplicado o **Grid Search com Valida√ß√£o Cruzada** para otimizar hiperpar√¢metros como `n_estimators`, `max_depth` e `min_samples_split`.

### 6.2 Resultados Finais no Conjunto de Teste

O modelo otimizado foi avaliado no **Conjunto de Teste**, garantindo uma avalia√ß√£o imparcial.

| M√©trica | RF Padr√£o (Valida√ß√£o) | RF Otimizado (TESTE) |
| :--- | :--- | :--- |
| **R¬≤** | $\mathbf{0.9567}$ | $\mathbf{0.9562}$ |
| **MAE** | $\mathbf{4.4930}$ | $\mathbf{4.6510}$ |

* **Conclus√£o da Otimiza√ß√£o:** O processo de *tuning* **n√£o resultou em um ganho significativo** na performance do $\text{R¬≤}$ no conjunto de teste (queda marginal de $0.9567$ para $0.9562$). Isso sugere que o modelo **Random Forest** j√° estava operando pr√≥ximo ao seu ponto ideal com os par√¢metros padr√£o.
* **Melhores Par√¢metros:** Os hiperpar√¢metros vencedores foram: `{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}`.

---

## 7. Conclus√µes

### 7.1 Resultados Alcan√ßados

O projeto atingiu seu objetivo de prever a nota final dos estudantes com alta acur√°cia, com o modelo final apresentando $\mathbf{R¬≤ = 0.9562}$ e $\mathbf{MAE = 4.65}$ no conjunto de teste. O $\text{Baseline}$ ($0.65$) foi superado por uma margem robusta.

| M√©trica | Baseline (R¬≤ = 0.65) | RF Padr√£o (Valida√ß√£o) | RF Otimizado (TESTE) |
| :--- | :--- | :--- | :--- |
| **R¬≤** | 0.65 | **0.956733** | **0.956242** |
| **MAE** | N/A | **4.492973** | **4.650987** |

* **Conclus√£o da Otimiza√ß√£o:** O processo de *tuning* **n√£o resultou em um ganho significativo** na performance do $\text{R¬≤}$ no conjunto de teste (queda marginal de $0.9567$ para $0.9562$). Isso sugere que o modelo Random Forest j√° estava operando pr√≥ximo ao seu ponto ideal com os par√¢metros padr√£o.
* **Melhores Par√¢metros:** Os hiperpar√¢metros vencedores foram: `{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}`.

### 7.2 Limita√ß√µes e An√°lise de Erros

1.  **Res√≠duos:** A distribui√ß√£o dos res√≠duos **√© aleat√≥ria e centrada em zero**, indicando que o modelo n√£o possui vi√©s sistem√°tico.
2.  **Casos Extremos:** Os casos de maior erro absoluto (analisados na C√©lula 9) geralmente ocorreram em situa√ß√µes onde **o modelo subestimou valores reais muito altos da `Pontuacao_Prova_Final`**, o que √© uma limita√ß√£o comum em modelos de √°rvore que n√£o extrapolam bem.

### 7.3 Trabalhos Futuros

1.  **Testar Algoritmos:** Avaliar o desempenho de outros modelos de *boosting*, como o **XGBoost** e **LightGBM**.
2.  **Feature Engineering:** Explorar *features* de intera√ß√£o mais complexas para melhorar a performance marginal restante.s